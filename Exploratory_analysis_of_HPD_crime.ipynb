{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exploratory analysis of HPD crime.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaoyangxuoo/Houston_crime_prevention/blob/master/Exploratory_analysis_of_HPD_crime.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xti7UQbDfSR7"
      },
      "source": [
        "### The first section, combining all data and read all data to dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rp76TpQxeCq"
      },
      "source": [
        "### Link for HPD crime data: https://drive.google.com/drive/folders/1p-cn9XjDSjoUPlPj0cBsgWNqbxlcGgK4?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD3KtALj-fj6"
      },
      "source": [
        "%%time \n",
        "# ########   Here is a link for geopandas usage: https://colab.research.google.com/github/shakasom/GDS/blob/master/Part1%20-%20Introduction.ipynb#scrollTo=6pMKuuyNMnwv\n",
        "# # Important library for many geopython libraries\n",
        "# !apt install gdal-bin python-gdal python3-gdal \n",
        "# # Install rtree - Geopandas requirment\n",
        "# !apt install python3-rtree \n",
        "# # Install Geopandas\n",
        "# !pip install git+git://github.com/geopandas/geopandas.git\n",
        "# # Install descartes - Geopandas requirment\n",
        "# !pip install descartes \n",
        "# # Install Folium for Geographic data visualization\n",
        "# !pip install folium\n",
        "# # Install plotlyExpress\n",
        "# !pip install plotly_express\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr1WnThS8oCQ"
      },
      "source": [
        "import sys\n",
        "print(sys.version)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOimNBXRTnWq"
      },
      "source": [
        "!pip install quickda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOl4lK0pTn0W"
      },
      "source": [
        "!pip install pandas-profiling==2.8.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXT2aGQvh7q6"
      },
      "source": [
        "#data = os.path.join('/content/gdrive/My Drive/HPD crime statistics', 'HPD 2019.xlsx')\n",
        "#df = pd.read_excel(data,header=0)\n",
        "\n",
        "data = os.path.join('/content/gdrive/My Drive/GIT project', 'HPD 2019.xlsx')\n",
        "df = pd.read_excel(data,header=0)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7q5Kad01iv0"
      },
      "source": [
        "########## Call quickda package to do the EDA for me!\n",
        "import os\n",
        "from quickda.explore_data import *\n",
        "from quickda.clean_data import *\n",
        "from quickda.explore_numeric import *\n",
        "from quickda.explore_categoric import *\n",
        "from quickda.explore_numeric_categoric import *\n",
        "from quickda.explore_time_series import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNRQSKIxUCTN"
      },
      "source": [
        "# explore(df, method=\"profile\", report_name=\"Dataset Report\", \n",
        "#         is_large_dataset=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVm_bAlmee5E"
      },
      "source": [
        "df.drop(columns=['Incident','Street\\nType','Block Range','Suffix'],inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBk1Eew5unGK"
      },
      "source": [
        "df = df.rename(columns={'Occurrence\\nDate':'Date', 'Occurrence\\nHour':'Hour', 'NIBRS\\nClass':'Reporting_Class','NIBRSDescription':'Category','Offense\\nCount':'Count','ZIP Code':'Zip_Code'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voRHY64YxBpj"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5TA6Yrmx83h"
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SlOW_evZIv_"
      },
      "source": [
        "## Convert descriptions to string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTIfFtgCxCcL"
      },
      "source": [
        "####convert descriptions to string\n",
        "df[[\"Zip_Code\",\"Reporting_Class\",'Category','Beat', 'Premise','StreetName','City']] = df[[\"Zip_Code\",\"Reporting_Class\",'Category','Beat', 'Premise','StreetName','City']].astype(str) \n",
        "##############truncate zip code\n",
        "df['Zip_Code'] = df['Zip_Code'].apply(lambda x: x[:5])\n",
        "df['Zip_Code_Numeric'] = df['Zip_Code'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA-9rFTEz_3z"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67Z4baroaiTn"
      },
      "source": [
        "## Finding outliers of each numerical column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqYXT_FJc01j"
      },
      "source": [
        "# import seaborn as sns\n",
        "# ######Helper function using z_score to detect the outlier\n",
        "# def detect_outlier(data_1):\n",
        "#     outliers = []\n",
        "#     threshold = 3\n",
        "#     mean_1 = np.mean(data_1)\n",
        "#     std_1 =np.std(data_1)    \n",
        "    \n",
        "#     for y in data_1:\n",
        "#         z_score= (y - mean_1)/std_1 \n",
        "#         if np.abs(z_score) > threshold:\n",
        "#             outliers.append(y)\n",
        "#     return outliers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBHdFoR2ctzz"
      },
      "source": [
        "### First column: Hour"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92JLNa7mykhB"
      },
      "source": [
        "# sns.boxplot(x=df['Hour'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVyBkiXiZk1f"
      },
      "source": [
        "# detect_outlier(df['Hour'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwPfO8XdabK-"
      },
      "source": [
        "### Second column: Count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4nFPPCmeRmU"
      },
      "source": [
        "# sns.boxplot(x=df['Count'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO91F1f0eTyV"
      },
      "source": [
        "# detect_outlier(df['Count'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opi0uL9FedOk"
      },
      "source": [
        "# df['Count'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6we0KOReYUh"
      },
      "source": [
        "# df[df['Count']==65]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcWa7nutenF1"
      },
      "source": [
        "# df[df['Count']==10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS2ra1i8euih"
      },
      "source": [
        "# df[df['Count']==1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOMOJTbgAnDZ"
      },
      "source": [
        "# Factors that may need to be considered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOt_PdgB3oGj"
      },
      "source": [
        "1) poverty : ##http://www.houstonstateofhealth.com/indicators/index/view?indicatorId=240&localeId=38555\n",
        "  drug\n",
        "  property\n",
        "  aggravated assault, violent crimes\n",
        "2) weather: \n",
        "3) average housing price (poverty moves to a different zip code\n",
        "4） education level: http://www.houstonstateofhealth.com/?module=demographicdata&controller=index&action=index&id=38500&sectionId=938\n",
        "5) political affiliation: \n",
        "6) utility usage\n",
        "7) public transportation density\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr-SKMF3fGCO"
      },
      "source": [
        "Therefore, it seems to be reasonable to group the count of each category and rank it from top to bottom"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG_OpD3Rgesq"
      },
      "source": [
        "# tempdf = df[['Category','Count']]\n",
        "# tempdf = tempdf.groupby(['Category']).sum()\n",
        "# Agg_cate = tempdf.reset_index()\n",
        "# Agg_cate.sort_values(by='Count',ascending = False, inplace=True)\n",
        "# Agg_cate = Agg_cate.reset_index(drop=True)\n",
        "# Agg_cate.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQBJhlrtzg_f"
      },
      "source": [
        "It looks like our city has the most crime being reported as theft from motor vehicle and simple assault."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyqQU9X_gfLX"
      },
      "source": [
        "### Last column: Zip code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSQaobrMfFby"
      },
      "source": [
        "#sns.boxplot(x=df['Zip_Code_Numeric'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yfWLEPrfdg9"
      },
      "source": [
        "# df['Zip_Code_Numeric'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X997sv2Wiy9S"
      },
      "source": [
        "It turns out that our dataset contains a lot of areas outside of Houston city limit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYTw2aIChGLQ"
      },
      "source": [
        "Houston_df = df[df['Zip_Code'].str.startswith('77')] ##### Restrict our analysis within Houston city limit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT581V-IDIrb"
      },
      "source": [
        "del df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_vH67WPiLG9"
      },
      "source": [
        "Houston_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylsvw77Jz1NL"
      },
      "source": [
        "The following plots can be done in quickDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN9EMwjBjigr"
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # An \"interface\" to matplotlib.axes.Axes.hist() method\n",
        "# n, bins, patches = plt.hist(x = Houston_df['Hour'], bins=10, color='#0504aa',\n",
        "#                             alpha=0.7, rwidth=0.85)\n",
        "# plt.grid(axis='y', alpha=0.75)\n",
        "# plt.xlabel('Hour')\n",
        "# plt.ylabel('Frequency')\n",
        "# plt.title('Histogram of crimes in Houston')\n",
        "# maxfreq = n.max()\n",
        "# # Set a clean upper y-axis limit.\n",
        "# plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIk3XCZy1_4P"
      },
      "source": [
        "With no doubt, the safest time of Houston is between 2am to 7am"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpNVPNvY2ZJs"
      },
      "source": [
        "## Next, I would like to see if there is a monthly pattern in the crime dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IhUA_lb2gvF"
      },
      "source": [
        "### First, we need to extract the months"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXQ81csm0jX4"
      },
      "source": [
        "Houston_df['Month'] = pd.DatetimeIndex(Houston_df['Date']).month"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKWf6qAC3wvL"
      },
      "source": [
        "Houston_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8GuW2984V47"
      },
      "source": [
        "# tempdf = Houston_df[['Month','Count']]\n",
        "# tempdf = tempdf.groupby(['Month']).sum()\n",
        "# Agg_mo = tempdf.reset_index()\n",
        "# Agg_mo.sort_values(by='Count',ascending = False, inplace=True)\n",
        "# Agg_mo = Agg_mo.reset_index(drop=True)\n",
        "# Agg_mo.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyUArxkB4wd1"
      },
      "source": [
        "It looks like the May and July is the most frequent crime dates which I think might be due to the weather? Not sure yet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpJayESpqhmS"
      },
      "source": [
        "## Then try to see the crime aggregation by premise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfN88D1X4t70"
      },
      "source": [
        "# tempdf = Houston_df[['Premise','Count']]\n",
        "# tempdf = tempdf.groupby(['Premise']).sum()\n",
        "# Agg_premise = tempdf.reset_index()\n",
        "# Agg_premise.sort_values(by='Count',ascending = False, inplace=True)\n",
        "# Agg_premise = Agg_premise.reset_index(drop=True)\n",
        "# Agg_premise.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZuJEM9BrIi6"
      },
      "source": [
        "## Lastly try to see the crime aggregation by zip_code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxkEZfm4rFd2"
      },
      "source": [
        "# tempdf = Houston_df[['Zip_Code','Count']]\n",
        "# tempdf = tempdf.groupby(['Zip_Code']).sum()\n",
        "# Agg_zip = tempdf.reset_index()\n",
        "# Agg_zip.sort_values(by='Count',ascending = False, inplace=True)\n",
        "# Agg_zip = Agg_zip.reset_index(drop=True)\n",
        "# Agg_zip.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30xPeN-Wrgzr"
      },
      "source": [
        "It looks like the Chinatown of Houston suffers most crimes, and the University of Houston main campus neighbourhood also\n",
        "Therefore, I will try to aggregate the zip_code, premise, and category together and see if it helps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KPDq9hprSV-"
      },
      "source": [
        "# tempdf = Houston_df[['Zip_Code','Premise','Category','Count']]\n",
        "# tempdf = tempdf.groupby(['Zip_Code','Premise','Category']).sum()\n",
        "# Agg_all = tempdf.reset_index()\n",
        "# Agg_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKBMB1VFsWlY"
      },
      "source": [
        "#Agg_all.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn4r6AYFzjKP"
      },
      "source": [
        "Sort the counts within each group"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSVcyJBQt4b-"
      },
      "source": [
        "# All_zipcodes = Agg_all['Zip_Code'].unique()\n",
        "# result = []\n",
        "# for zip_code in All_zipcodes:\n",
        "#   temp_zip = Agg_all[Agg_all['Zip_Code']== zip_code]\n",
        "#   All_premises = temp_zip['Premise'].unique()\n",
        "#   for prem in All_premises:\n",
        "#     temp_prem = temp_zip[temp_zip['Premise']==prem]\n",
        "#     temp_prem = temp_prem.sort_values(by='Count',ascending=False)\n",
        "#     result.append(temp_prem)     \n",
        "# Final = pd.concat(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8YyRAwv2vkS"
      },
      "source": [
        "#Final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJVQAcjMziS_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9rpDph2YXAr"
      },
      "source": [
        "Houston_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0FOFNlwYYC4"
      },
      "source": [
        "!pip install catboost\n",
        "!pip install -U scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig2hftnxYczl"
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# import catboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3CcBAvtZaWm"
      },
      "source": [
        "# train, validation = train_test_split(Houston_df, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4UTM-DqZslj"
      },
      "source": [
        "# def gen_pool(train, in_feature, out_feature):\n",
        "#   train_pool = catboost.Pool(train[in_feature], train[out_feature], cat_features=train[in_feature].columns[train[in_feature].dtype=='object'])\n",
        "#   return train_pool"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZyASQYlIg-G"
      },
      "source": [
        "## Collecting feature vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kexFzWRAbk36"
      },
      "source": [
        "from pathlib import Path\n",
        "#directory = '/content/gdrive/My Drive/HPD crime statistics/Feature data'\n",
        "directory = '/content/gdrive/My Drive/GIT project/Feature data'\n",
        "feature_dfs = []\n",
        "for filename in os.listdir(directory):\n",
        "    f = os.path.join(directory, filename)\n",
        "    print(f)\n",
        "    if f.endswith(\".csv\"):\n",
        "      feature_dfs.append(pd.read_csv(f))\n",
        "\n",
        "print(len(feature_dfs))\n",
        "poverty_df = feature_dfs[0]\n",
        "poverty_df.head()\n",
        "poverty_df = poverty_df[poverty_df['Period of Measure'].str[-4:]=='2019']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LC48Y35IqWe"
      },
      "source": [
        "poverty_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwZTs0PjJRXo"
      },
      "source": [
        "final_df = Houston_df.merge(poverty_df[['Location', 'Indicator Rate Value']],\n",
        "               left_on='Zip_Code_Numeric', right_on='Location', how='left')\n",
        "final_df.head()\n",
        "#Houston_df.drop(columns=['Location_x', 'Indicator Rate Value_x','Location_y'],inplace=True).rename(columns={'Indicator Rate Value_y': 'poverty rate'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq-HJu9TUn9x"
      },
      "source": [
        "final_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uFNZ8XP81iR"
      },
      "source": [
        "# delete all the references to poverty table to release memory\n",
        "del poverty_df\n",
        "del feature_dfs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6Dej4QpOf9z"
      },
      "source": [
        "###### Filter out the 2019, the only relevant data columns\n",
        "housing_df = feature_dfs[1]\n",
        "filter_cols = ['RegionName', 'StateName', 'State', 'City']\n",
        "temp = [col for col in housing_df.columns if col.startswith('2019')]\n",
        "filter_cols.extend(temp)\n",
        "housing_df_2019 = housing_df[filter_cols]\n",
        "housing_df_2019 = housing_df_2019[(housing_df_2019['State']== 'TX') & (housing_df_2019['StateName'] == 'TX') & (housing_df_2019['City'] == 'Houston')]\n",
        "housing_df_2019 = housing_df_2019.drop(['StateName', 'State', 'City'], axis=1)\n",
        "housing_df_2019.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8tbLj16RUUd"
      },
      "source": [
        "final_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4M2Xitr3eEm"
      },
      "source": [
        "sum(housing_df_2019['RegionName'].isin([77489]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3oFT9IIc-LJ"
      },
      "source": [
        "# melt housing_df data from wide format to long format\n",
        "def melt(df, col_vals, key, value):\n",
        "    keep_vals = df.columns.difference(col_vals)\n",
        "    melted_sections = []\n",
        "    for c in col_vals:\n",
        "        melted_c = df[keep_vals].copy()\n",
        "        melted_c[key] = c\n",
        "        melted_c[value] = df[c]\n",
        "        melted_sections.append(melted_c)\n",
        "    return pd.concat(melted_sections)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5hRLo4XjleQ"
      },
      "source": [
        "housing_melt = melt(housing_df_2019, [\"2019-01-31\", \"2019-02-28\", \"2019-03-31\", \"2019-04-30\", \"2019-05-31\", \"2019-06-30\", \\\n",
        "                                       \"2019-07-31\", \"2019-08-31\", \"2019-09-30\", \"2019-10-31\", \"2019-11-30\", \"2019-12-31\"], key='Time', value='Housing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpORRgCzlp-B"
      },
      "source": [
        "housing_melt['Time'] = pd.to_datetime(housing_melt['Time'], format='%Y-%m-%d')\n",
        "housing_melt['Month'] = housing_melt['Time'].dt.month"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM7-xPR0kyG1"
      },
      "source": [
        "# combine housing_melt with Houston_df_w_poverty\n",
        "final_df = final_df.merge(housing_melt[['RegionName', 'Month', 'Housing']],\n",
        "               left_on=['Month',\"Zip_Code_Numeric\"], right_on=['Month','RegionName'], how='left')\n",
        "final_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIaRPWb3qo_P"
      },
      "source": [
        "final_df[final_df['Zip_Code_Numeric'] == 77084].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN1x8ODgUtqZ"
      },
      "source": [
        "final_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaPC1iAC89LC"
      },
      "source": [
        "del housing_df_2019\n",
        "del feature_dfs[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eoey5DFj_8SJ"
      },
      "source": [
        "### The following code requires 13 min + to run, which is inefficient, but doable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQK_ua7RRoVs"
      },
      "source": [
        "# Houston_df_w_poverty['Housing Price'] = 0.0\n",
        "# #import math\n",
        "# for idx, row in Houston_df_w_poverty.iterrows():\n",
        "#   mon = Houston_df_w_poverty.loc[idx, 'Date']\n",
        "#   mon = mon.strftime(\"%m\")\n",
        "#   #print(mon)\n",
        "#   filter_cols = [col for col in housing_df_2019.columns if col[5:7] == mon]\n",
        "#   filter_cols.append('RegionName')\n",
        "#   temp = housing_df_2019[filter_cols]\n",
        "#   # print(temp.head)\n",
        "#   # break\n",
        "#   if  temp[temp['RegionName']==Houston_df_w_poverty.loc[idx,'Zip_Code_Numeric']].values.size == 0:\n",
        "#     continue\n",
        "#   else:\n",
        "#     Houston_df_w_poverty.loc[idx, 'Housing Price'] = temp[temp['RegionName']==Houston_df_w_poverty.loc[idx,'Zip_Code_Numeric']].iloc[0, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2sr1ha7fDLF"
      },
      "source": [
        "weather_df = feature_dfs[0]\n",
        "weather_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHf_EejJgkks"
      },
      "source": [
        "weather_df = weather_df[['Date time', 'Temperature', 'Conditions']]\n",
        "weather_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtMe0n2BELdB"
      },
      "source": [
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None  # default='warn'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wfsHSUSfSCg"
      },
      "source": [
        "weather_df['time'] = pd.to_datetime(weather_df['Date time'], format='%m/%d/%Y %H:%M:%S')\n",
        "weather_df['Hour'] = weather_df['time'].dt.hour\n",
        "weather_df['Date'] = weather_df['time'].dt.date\n",
        "weather_df['Date'] = pd.to_datetime(weather_df['Date'])\n",
        "weather_df = weather_df[weather_df['time'].dt.year == 2019]\n",
        "weather_df = weather_df.drop(['Date time','time'], axis = 1)\n",
        "weather_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iAbtXHAevQY"
      },
      "source": [
        "# delete duplicates in weather data\n",
        "weather_df = weather_df.drop_duplicates(subset=['Hour', 'Date'], keep='first')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deWTynrt05ry"
      },
      "source": [
        "# merge weather data according to date and hour\n",
        "final_df = final_df.merge(weather_df[['Temperature', 'Conditions', 'Hour', 'Date']],\n",
        "               left_on=['Date','Hour'], right_on=['Date','Hour'], how='left')\n",
        "final_df.rename(columns = {'Indicator Rate Value': 'Poverty_rate', 'Conditions':\n",
        "                                               'Weather_conditions'}, inplace = True)\n",
        "final_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwyKTnGmUwEa"
      },
      "source": [
        "final_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9qQ0WYS9Bd6"
      },
      "source": [
        "del weather_df\n",
        "del feature_dfs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBK0WxGQ-Bhm"
      },
      "source": [
        "unemploy_df = feature_dfs[0]\n",
        "unemploy_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dDSGZ7b_uPv"
      },
      "source": [
        "unemploy_df = unemploy_df[unemploy_df['Year'] == 2019]\n",
        "m = {'M01':1, 'M02':2, 'M03':3, 'M04':4, 'M05':5, 'M06':6, 'M07':7, 'M08':8, 'M09':9, 'M10':10, 'M11':11, 'M12':12}\n",
        "unemploy_df['Month'] = unemploy_df.Period.map(m)\n",
        "unemploy_df = unemploy_df.drop(['Series ID','Period','Label'], axis = 1)\n",
        "unemploy_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIWQOcvnEHj8"
      },
      "source": [
        "final_df['Year'] = final_df.Date.dt.year"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvdNi7ubCIK1"
      },
      "source": [
        "# merge unemployment data according to year and month\n",
        "final_df = final_df.merge(unemploy_df[['Year', 'Value', 'Month']],\n",
        "               left_on=['Year','Month'], right_on=['Year','Month'], how='left')\n",
        "final_df.rename(columns = {'Value': 'Unemploy_value'}, inplace = True)\n",
        "final_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTF-suPzUx4C"
      },
      "source": [
        "final_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyM0PV3G9Fir"
      },
      "source": [
        "del unemploy_df\n",
        "del feature_dfs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwG7rNKUEXyk"
      },
      "source": [
        "income_df = feature_dfs[0]\n",
        "income_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNLlFVFPRsZg"
      },
      "source": [
        "income_df = income_df[income_df['Period of Measure'] == '2015-2019']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQb8hzDbE9FZ"
      },
      "source": [
        "# merge Median Household Income data according to zipcode\n",
        "final_df = final_df.merge(income_df[['Location', 'Indicator Rate Value']],\n",
        "               left_on=['Zip_Code_Numeric'], right_on=['Location'], how='left')\n",
        "final_df.rename(columns = {'Indicator Rate Value': 'Median_household_income'}, inplace = True)\n",
        "final_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PnFNabzUzuT"
      },
      "source": [
        "final_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5xAmeCQ9H4Z"
      },
      "source": [
        "del income_df\n",
        "del feature_dfs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erC8Ln-8FtgN"
      },
      "source": [
        "# bachelor_df = feature_dfs[0]\n",
        "# bachelor_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw-bq9zGF7c9"
      },
      "source": [
        "# # merge 25+ with Bachelor or higher data according to zipcode\n",
        "# final_df = final_df.merge(bachelor_df[['Location', 'Indicator Rate Value']],\n",
        "#                left_on=['Zip_Code_Numeric'], right_on=['Location'], how='left')\n",
        "# final_df.rename(columns = {'Indicator Rate Value': '25+_w_bachelor_or_higher_in_percent'}, inplace = True)\n",
        "# final_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-y3yO6n9L0x"
      },
      "source": [
        "# del bachelor_df\n",
        "# del feature_dfs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-Dy8HvoGrnQ"
      },
      "source": [
        "high_school_df = feature_dfs[1]\n",
        "high_school_df.head() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUODnP3hS7a0"
      },
      "source": [
        "high_school_df = high_school_df[high_school_df['Period of Measure'] == '2015-2019']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb8IliCdJEYm"
      },
      "source": [
        "# merge 25+ with high school or higher data according to zipcode\n",
        "final_df = final_df.merge(high_school_df[['Location', 'Indicator Rate Value']],\n",
        "               left_on=['Zip_Code_Numeric'], right_on=['Location'], how='left')\n",
        "final_df.rename(columns = {'Indicator Rate Value': '25+_w_high_school_or_higher_in_percent'}, inplace = True)\n",
        "final_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9dyGDra9N7r"
      },
      "source": [
        "del high_school_df\n",
        "del feature_dfs[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spDjwm91Ty8_"
      },
      "source": [
        "Houston_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zibP_qWZTtTX"
      },
      "source": [
        "final_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3he5p7cLk5b9"
      },
      "source": [
        "from google.colab import files\n",
        "final_df.to_csv('Final.csv') \n",
        "files.download('Final.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laD8Me1LKI5W"
      },
      "source": [
        "# # merge per_capita_income data according to zipcode\n",
        "# final_df = final_df.merge(per_capita_income[['Location', 'Indicator Rate Value']],\n",
        "#                left_on=['Zip_Code_Numeric'], right_on=['Location'], how='left')\n",
        "# final_df.rename(columns = {'Indicator Rate Value': 'Per_capita_income'}, inplace = True)\n",
        "# final_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEAJD5k_9Ppi"
      },
      "source": [
        "# del per_capita_income\n",
        "# del feature_dfs[0]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}